{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 14: Machine Learning Classification - Student Lab\n",
    "\n",
    "## Titanic Survival Prediction Challenge\n",
    "\n",
    "Welcome to the hands-on lab for machine learning classification! In this lab, you'll apply what you've learned about classification algorithms to predict Titanic passenger survival.\n",
    "\n",
    "### Learning Objectives:\n",
    "- Practice data preprocessing for machine learning\n",
    "- Implement and compare different classification algorithms\n",
    "- Evaluate model performance using appropriate metrics\n",
    "- Handle overfitting and perform cross-validation\n",
    "- Interpret feature importance and model results\n",
    "\n",
    "### Instructions:\n",
    "1. Follow the TODO comments to complete each section\n",
    "2. Run all cells in order\n",
    "3. Answer the questions in the markdown cells\n",
    "4. Experiment with different parameters and techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== Module 14: Machine Learning Classification Lab ===\")\n",
    "print(\"Titanic Survival Prediction Challenge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Exploration\n",
    "\n",
    "**TODO 1.1:** Load the Titanic dataset and examine its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.1: Load the Titanic dataset\n",
    "# Hint: Use pd.read_csv() with the URL provided\n",
    "titanic = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Dataset shape: {titanic.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(titanic.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(titanic.describe())\n",
    "\n",
    "# Data types and missing values\n",
    "print(\"\\nData types and missing values:\")\n",
    "print(titanic.info())\n",
    "print(\"\\nMissing values count:\")\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1:** What are the key characteristics of this dataset? How many passengers? What types of features? What are the main missing value issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1.2:** Create visualizations to understand the relationships between features and survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.2: Create exploratory visualizations\n",
    "# Hint: Use seaborn for bar plots, histograms, and correlation heatmaps\n",
    "\n",
    "# Survival rate by different categorical features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Survival by Sex\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Survival by Pclass\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Survival by Embarked\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Age distribution by survival\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap (you'll need to preprocess first for this)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2:** Which features seem most correlated with survival? Why might this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Preprocessing\n",
    "\n",
    "**TODO 2.1:** Implement data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.1: Implement data preprocessing\n",
    "def preprocess_data(df):\n",
    "    # Create a copy\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Handle missing Age values\n",
    "    # Hint: Use median age by Pclass and Sex\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Handle missing Embarked values\n",
    "    # Hint: Fill with mode\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Handle missing Fare values (if any)\n",
    "    # Hint: Use median fare by Pclass\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Create Has_Cabin feature from Cabin column\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Extract Title from Name\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Create Family_Size and Is_Alone features\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    # Hint: Use LabelEncoder for Sex, Embarked, Title\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Apply preprocessing\n",
    "titanic_clean = preprocess_data(titanic)\n",
    "print(\"Preprocessed data shape:\", titanic_clean.shape)\n",
    "print(\"\\nRemaining missing values:\")\n",
    "print(titanic_clean.isnull().sum())\n",
    "\n",
    "# Display first few rows of preprocessed data\n",
    "print(\"\\nFirst 5 rows of preprocessed data:\")\n",
    "display(titanic_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 2.2:** Prepare features and target, then split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.2: Prepare features and split data\n",
    "# Separate features and target\n",
    "X = # YOUR CODE HERE\n",
    "y = # YOUR CODE HERE\n",
    "\n",
    "# Split into train and test sets\n",
    "# Hint: Use train_test_split with stratify=y and random_state=42\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Scale the features\n",
    "# Hint: Use StandardScaler\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Survival rate in training set: {y_train.mean():.2%}\")\n",
    "print(f\"Survival rate in test set: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2:** Why do we use stratified splitting? What does feature scaling do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model Training and Evaluation\n",
    "\n",
    "**TODO 3.1:** Train and evaluate multiple classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.1: Train and evaluate models\n",
    "# Define models dictionary\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    \n",
    "    # Train the model\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Make predictions\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Calculate metrics\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Cross-validation score\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'roc_auc': roc_auc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Which model performed best? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 3.2:** Compare models with ROC curves and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.2: Compare models\n",
    "# Create performance comparison table\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "display(model_comparison)\n",
    "\n",
    "# Plot ROC curves\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Model Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** What does the ROC curve tell us about model performance? How do you interpret the AUC score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Feature Importance and Overfitting Analysis\n",
    "\n",
    "**TODO 4.1:** Analyze feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.1: Feature importance analysis\n",
    "# Get the best performing model (Random Forest)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Plot feature importance\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "display(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1:** Which features are most important for predicting survival? Does this match your intuition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 4.2:** Analyze overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.2: Overfitting analysis\n",
    "# Compare training vs test performance for all models\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Plot training vs test performance\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Test Accuracy - Overfitting Analysis')\n",
    "plt.xticks(x, model_names, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2:** Which model shows signs of overfitting? How can you tell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Hyperparameter Tuning (Optional Advanced Challenge)\n",
    "\n",
    "**TODO 5.1:** Perform hyperparameter tuning on the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.1: Hyperparameter tuning (Optional)\n",
    "# Use GridSearchCV to tune Random Forest hyperparameters\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Fit the grid search\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test_scaled)\n",
    "y_pred_proba_tuned = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"\\nTuned Model Test Accuracy: {best_model.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"Tuned Model Test ROC-AUC: {roc_auc_score(y_test, y_pred_proba_tuned):.4f}\")\n",
    "\n",
    "# Compare with original model\n",
    "original_rf = results['Random Forest']['model']\n",
    "original_auc = results['Random Forest']['roc_auc']\n",
    "print(f\"\\nOriginal Random Forest ROC-AUC: {original_auc:.4f}\")\n",
    "print(f\"Improvement: {roc_auc_score(y_test, y_pred_proba_tuned) - original_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Reflection\n",
    "\n",
    "**TODO:** Complete the summary questions below\n",
    "\n",
    "### Key Learnings:\n",
    "1. What was the most surprising result from your analysis?\n",
    "2. Which model would you recommend for this prediction task and why?\n",
    "3. What are the most important features for predicting survival?\n",
    "4. How did you handle overfitting in your models?\n",
    "5. What would you do differently if you had more time/data?\n",
    "\n",
    "### Answers:\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n",
    "\n",
    "### Next Steps:\n",
    "- Try advanced techniques like stacking or feature selection\n",
    "- Experiment with different preprocessing approaches\n",
    "- Consider domain-specific features\n",
    "- Explore model interpretability techniques\n",
    "- Try RAPIDS GPU acceleration for larger datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}