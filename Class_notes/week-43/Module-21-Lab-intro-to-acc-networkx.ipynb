{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0HOzwNKXXic"
      },
      "source": [
        "# Lab: Introduction to NetworkX accelerated by NVIDIA cuGraph #\n",
        "\n",
        "## Table of Contents ##\n",
        "\n",
        "This Lab notebook explores the fundamentals of data acquisition and manipulation using the Graph analytics APIs of the library [NetworkX](https://networkx.org/), covering essential techniques for creating, manipulating, and studying graph based relationships. This notebook covers the below sections:\n",
        "\n",
        "1. [Introduction to NetworkX and NVIDIA cuGraph](#Introduction-to-NetworkX-and-NVIDIA-cuGraph)\n",
        "1. [Data Background](#Data-Background)\n",
        "1. [1. Environment Setup](#1.-Environment-Setup)\n",
        "1. [2. Form the Data into a NetworkX Graph](#2.-Form-the-Data-into-a-NetworkX-Graph)\n",
        "1. [3. Identify Which Cluster Contains the Most Important Patent](#3.-Identify-Which-Cluster-Contains-the-Most-Important-Patent)\n",
        "1. [4. Load the Enrichment Data Containing the Patent Titles](#4.-Load-the-Enrichment-Data-Containing-the-Patent-Titles)\n",
        "1. [Conclusion](#Conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN-d_DX3XXid"
      },
      "source": [
        "## Introduction to NetworkX and NVIDIA cuGraph ##\n",
        "\n",
        "NetworkX is the most popular Python graph analytics library.  Among other capabilities, it allows for the:\n",
        "\n",
        "- Creation of directed, undirected, weighted, bi, and multi graphs\n",
        "- Manipulation of graphs by adding or removing edges, nodes, metadata, and other modifications to the graph structure\n",
        "- Study the relationships between edges and nodes using many graph-based algorithms\n",
        "\n",
        "The ability to create, manipluate, and study these graphs allows researchers and professionals to model many types of relationships and processes in physical, biological, social and information systems. A graph consists of nodes or vertices (representing the entities in the system) that are connected by edges (representing relationships between those entities). By navigating the edges and nodes to discover and understand complex relationships and/or optimize paths between linked data in a network.\n",
        "\n",
        "The NetworkX open source project is led by community maintainers, and install instructions are [here](https://networkx.org/documentation/stable/install.html). It is readily accessible and free to download.\n",
        "\n",
        "NVIDIA [cuGraph](https://github.com/rapidsai/cugraph/) provides GPU acceleration for popular graph algorithms such as PageRank, Louvain, and betweenness centrality. Depending on the algorithm and graph size, it can significantly accelerate NetworkX workflows, up to 50x, even 500x over NetworkX on CPU.\n",
        "\n",
        "NetworkX now includes a [GPU backend powered by NVIDIA cuGraph](https://docs.rapids.ai/api/cugraph/stable/nx_cugraph/) that allows you to seamlessly handle large graphs - exceeding 100,000 nodes and 1 million edges - on a single GPU. This allows you to maintain the flexibility of NetworkX while dramatically improving performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGt_4GKKXXie"
      },
      "source": [
        "## Data Background ##\n",
        "For this lab, we'll be working with a couple of datasets containg patents and citations from [PatentsView](https://patentsview.org/download/data-download-tables).  Both files are used under the Creative Commons license https://creativecommons.org/licenses/by/4.0/\n",
        "\n",
        "The first file, g_patent.tsv.zip, contains summary data for each patent such as id, title and the location of the original patent document. The table description is available on the PatentsView site.\n",
        "\n",
        "The second file, g_us_patent_citation.tsv.zip, contains a record for every citation between USPatents. The description of this table is also available on the PatentsView site.\n",
        "\n",
        "Citation: U.S. Patent and Trademark Office. “Data Download Tables.” PatentsView. Accessed [10/06/2024]. https://patentsview.org/download/data-download-tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcYLGAPGXXie"
      },
      "source": [
        "## 1. Environment Setup #\n",
        "This notebook will demonstrate NetworkX both with and without acceleration by NVIDIA cuGraph\n",
        "\n",
        "The NetworkX open source project is led by community maintainers, and install instructions are [here](https://networkx.org/documentation/stable/install.html). It is readily accessible and free to download.\n",
        "\n",
        "\n",
        "### Importing and installing NetworkX and it's GPU accelerator backend ###\n",
        "\n",
        "To install both NetworkX and its accelerator, you can just run this command:\n",
        "\n",
        " `> pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com`\n",
        "\n",
        "Users can access the GPU backend using an environment variable. For more details, visit the [NetworkX](https://networkx.org/documentation/stable/reference/introduction.html) and [cuGraph](https://docs.rapids.ai/api/cugraph/stable/nx_cugraph/) documentation.\n",
        "\n",
        "To begin, let's install NetworkX, nx-cugraph, and cuDF for the pandas GPU accelerator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmWcxlybXXie"
      },
      "outputs": [],
      "source": [
        "!pip install nx-cugraph-cu12 cudf-cu12 --extra-index-url=https://pypi.nvidia.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UmsA-zQXXif"
      },
      "source": [
        "This notebook will be using features added in NetworkX version 3.3+, so we'll import it here to verify we have a compatible version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDm2muUYXXif"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "nx.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "WARNING: If your NetworkX is below version `3.3`, please uncomment the cell below to upgrade NetworkX, as well as restart the jupyter notebook kernel.  Then, please check the NetworkX version again by rerunning the cell above before proceeding on with the rest of the lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install networkx --upgrade\n",
        "# get_ipython().kernel.do_shutdown(restart=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSeI0qjNXXif"
      },
      "source": [
        "Now, let's configure the NetworkX backend to use cuGraph for it's GPU acceleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4gB43HSXXif"
      },
      "outputs": [],
      "source": [
        "nx.config.backend_priority=[\"cugraph\"]  # NETWORKX_BACKEND_PRIORITY=cugraph\n",
        "nx.config.cache_converted_graphs=True   # NETWORKX_CACHE_CONVERTED_GRAPHS=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7nHpd7vXXif"
      },
      "source": [
        "Just to make the output cleaner, we'll ignore warnings about using a cahced graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC6yq7aCXXif"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Using cached graph for 'cugraph' backend\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9JVXY2Ivdb"
      },
      "source": [
        "### Download the Data\n",
        "\n",
        "In order to complete this lab, please download from [here](https://poloclub.github.io/data-science-teaching-kit/).\n",
        "Now you are all set up for completing this lab!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMAQuirnXXif"
      },
      "outputs": [],
      "source": [
        "# Download and unzip files if they do not exist\n",
        "!if [ ! -f \"./g_us_patent_citation.tsv.zip\" ]; then curl \"https://s3.amazonaws.com/data.patentsview.org/download/g_us_patent_citation.tsv.zip\" -o ./g_us_patent_citation.tsv.zip; else echo \"Population dataset found\"; fi\n",
        "!if [ ! -f \"./g_us_patent_citation.tsv\" ]; then unzip -d ./ ./g_us_patent_citation.tsv.zip\n",
        "\n",
        "!if [ ! -f \"./g_patent.tsv.zip\" ]; then curl \"https://s3.amazonaws.com/data.patentsview.org/download/g_patent.tsv.zip\" -o ./g_patent.tsv.zip; else echo \"Population dataset found\"; fi\n",
        "!if [ ! -f \"./g_patent.tsv\" ]; then unzip -d ./ ./g_patent.tsv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4haAYjoSGBM"
      },
      "source": [
        "## 2. Form the Data into a NetworkX Graph ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRlTbjIvSqHM"
      },
      "source": [
        "#### Q1. Load the citation Data into a pandas Dataframe\n",
        "\n",
        "Read the patent citation dataset (g_us_patent_citation.tsv) using `pandas.read_csv()` and save the data to `pandas.DataFrame` variables. Additionally, measure the time taken to read each dataset for later use. Use cudf pandas to accelerate dataloading with the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot1_FujnRjKf"
      },
      "outputs": [],
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "\n",
        "# TODO: Read the citation dataset using pd.read_csv() and find the length of the resulting dataframe\n",
        "\n",
        "citation_df = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDU6TF-hXXig"
      },
      "source": [
        "Since the dataframe is using [cuDF pandas Accelerator Mode](https://rapids.ai/cudf-pandas/), accessing it is fast !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUJrwqXOXXig"
      },
      "outputs": [],
      "source": [
        "len(citation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvZm_BBpSwAv"
      },
      "source": [
        "#### Q2. Create a NetworkX Graph from the dataset and count the edges in the graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4unFGuzXXig"
      },
      "source": [
        "This will take a few minutes. It is using NetworkX to create a 142 million edge graph on the cpu. This is a necessary overhead for loading the graph that will be later transformed into the cuGraph GPU-resident graph that will be reused in each algorithm we call, accelerating those algorithms dramatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWuXkIx3TBYm"
      },
      "outputs": [],
      "source": [
        "# TODO: Create the graph using NetworkX from_pandas_edgelist function\n",
        "\n",
        "# measure the running time on each dataset and append to sklearn_running_times\n",
        "G = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_qSmvAaSjwE"
      },
      "source": [
        "### 3. Identify Which Cluster Contains the Most Important Patent ###\n",
        "Run PageRank to find the most important patent in the citation graph and then cluster the graph using Louvain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8ftUDOKTVC8"
      },
      "source": [
        "#### Q3. What is the most important patent\n",
        "\n",
        "Run pagerank on the citation dataset, save the most important patent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaHo-5B5R0hx"
      },
      "outputs": [],
      "source": [
        "# TODO: run pagerank on the graph using the cuGraph backend\n",
        "\n",
        "pr_results = []\n",
        "# rerun the pagerank to see how prebuilding the graph effects the alrithm run time.\n",
        "# sort the results to find the most important patent and save it\n",
        "mip = []\n",
        "most_important_patent = mip[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSTPIquhTqvk"
      },
      "source": [
        "#### Q4. Call Louvain algorithm to create clusters. Find which cluster contains the most important patent and save it\n",
        "Use the cugraph backend to execute louvain on the citation graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evSjCKMnLpOb"
      },
      "outputs": [],
      "source": [
        "clusters = []\n",
        "\n",
        "# This cluster contains most important patent\n",
        "save_cluster = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdX8FjI10K6R"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXUNhqtPqqVK"
      },
      "source": [
        "### 4. Load the Enrichment Data Containing the Patent Titles ###\n",
        "#### Q5. How can we use more data to enrich the graph clusters? ####\n",
        "Create a dataframe with the patent id and title using the read_csv function\n",
        "Enrich the cluster by merging the cluster ids with the dataframe containing the ids and titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDfUwZIR1yK-"
      },
      "outputs": [],
      "source": [
        "#TODO: Read the g_patent.tsv file into a dataframe and merge with the save_cluster with merge how=\"inner\" parameter\n",
        "cluster_df = []\n",
        "enriched_df = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRzirsT_XXih"
      },
      "source": [
        "## Conclusion ##\n",
        "**Well Done!**\n",
        "In this lab, you have learned how basic usage and how to study relationships through graphs  using the NetworkX library and the GPU accelerated backend.  :\n",
        "\n",
        "1. [Set up the NetworkX environment](#1.-Environment-Setup)\n",
        "1. [How to form the tabular data into a NetworkX graph](#2.-Form-the-Data-into-a-NetworkX-Graph)\n",
        "1. Use NetworkX to understand the [relationships in the graph](#3.-Identify-Which-Cluster-Contains-the-Most-Important-Patent) such as\n",
        "    - Finding out the most important patents\n",
        "    - Understanding communities of patents\n",
        "    - Which are the most important clusters\n",
        "    - [improving a graph's power using data enrichment](#4.-Load-the-Enrichment-Data-Containing-the-Patent-Titles)\n",
        "\n",
        "Continue your GPU accelerated data science journey by going to https://github.com/rapidsai-community/showcase/tree/main/accelerated_data_processing_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtZk6ItEXXih"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
