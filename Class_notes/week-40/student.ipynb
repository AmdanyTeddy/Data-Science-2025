{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 15: Machine Learning Clustering and Dimensionality Reduction - Student Lab\n",
    "\n",
    "## Titanic Dataset: Unsupervised Learning Challenge\n",
    "\n",
    "Welcome to the hands-on lab for unsupervised machine learning! In this lab, you'll discover hidden patterns in the Titanic dataset using clustering and dimensionality reduction techniques.\n",
    "\n",
    "### Learning Objectives:\n",
    "- Practice data preprocessing for unsupervised learning\n",
    "- Implement and compare different clustering algorithms\n",
    "- Apply dimensionality reduction techniques\n",
    "- Evaluate clustering results using appropriate metrics\n",
    "- Interpret clusters and understand their real-world meaning\n",
    "- Use RAPIDS for GPU acceleration (if available)\n",
    "\n",
    "### Instructions:\n",
    "1. Follow the TODO comments to complete each section\n",
    "2. Run all cells in order\n",
    "3. Answer the questions in the markdown cells\n",
    "4. Experiment with different parameters and techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import RAPIDS libraries\n",
    "try:\n",
    "    import cuml\n",
    "    import cudf\n",
    "    RAPIDS_AVAILABLE = True\n",
    "    print(\"RAPIDS libraries available for GPU acceleration\")\n",
    "except ImportError:\n",
    "    RAPIDS_AVAILABLE = False\n",
    "    print(\"RAPIDS libraries not available, using CPU implementations\")\n",
    "\n",
    "# Try to import UMAP\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "    print(\"UMAP library available\")\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"UMAP library not available\")\n",
    "\n",
    "print(\"\\n=== Module 15: Unsupervised Learning Lab ===\")\n",
    "print(\"Titanic Dataset Clustering and Dimensionality Reduction Challenge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Preprocessing\n",
    "\n",
    "**TODO 1.1:** Load the Titanic dataset and examine its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.1: Load the Titanic dataset\n",
    "# Hint: Use pd.read_csv() with the URL provided\n",
    "titanic = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Dataset shape: {titanic.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(titanic.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(titanic.describe())\n",
    "\n",
    "# Data types and missing values\n",
    "print(\"\\nData types and missing values:\")\n",
    "print(titanic.info())\n",
    "print(\"\\nMissing values count:\")\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1:** What are the main challenges with this dataset for unsupervised learning? How does it differ from supervised learning preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1.2:** Implement data preprocessing for unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1.2: Implement data preprocessing\n",
    "def preprocess_unsupervised(df):\n",
    "    # Create a copy\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Handle missing Age values\n",
    "    # Hint: Use median age by Pclass and Sex\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Handle missing Embarked values\n",
    "    # Hint: Fill with mode\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Handle missing Fare values (if any)\n",
    "    # Hint: Use median fare by Pclass\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Create Has_Cabin feature from Cabin column\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Extract Title from Name\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Create Family_Size feature\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    # Hint: Use LabelEncoder for Sex, Embarked, Title\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Keep PassengerId and Survived for later analysis\n",
    "    passenger_info = df_clean[['PassengerId', 'Survived', 'Name']].copy()\n",
    "    \n",
    "    # Drop unnecessary columns for clustering\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return df_clean, passenger_info\n",
    "\n",
    "# Apply preprocessing\n",
    "titanic_clean, passenger_info = preprocess_unsupervised(titanic)\n",
    "print(\"Preprocessed data shape:\", titanic_clean.shape)\n",
    "print(\"\\nRemaining missing values:\")\n",
    "print(titanic_clean.isnull().sum())\n",
    "\n",
    "# Scale the features\n",
    "# Hint: Use StandardScaler\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"\\nScaled data shape:\", titanic_scaled.shape)\n",
    "print(\"\\nScaled data statistics:\")\n",
    "display(titanic_scaled.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2:** Why do we need to scale features for clustering? What happens if we don't scale them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: K-means Clustering\n",
    "\n",
    "**TODO 2.1:** Determine the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.1: Determine optimal number of clusters\n",
    "# Use Elbow method and Silhouette analysis\n",
    "# Hint: Try k from 2 to 10\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = # YOUR CODE HERE\n",
    "\n",
    "for k in K_range:\n",
    "    if RAPIDS_AVAILABLE:\n",
    "        # Use RAPIDS cuML\n",
    "        kmeans = # YOUR CODE HERE\n",
    "        kmeans.fit(titanic_scaled)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        labels = kmeans.labels_\n",
    "    else:\n",
    "        # Use scikit-learn\n",
    "        kmeans = # YOUR CODE HERE\n",
    "        kmeans.fit(titanic_scaled)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        labels = kmeans.labels_\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    sil_score = silhouette_score(titanic_scaled, labels)\n",
    "    silhouette_scores.append(sil_score)\n",
    "\n",
    "# Plot Elbow method and Silhouette scores\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print optimal k suggestions\n",
    "optimal_k_elbow = # YOUR CHOICE BASED ON PLOT\n",
    "optimal_k_silhouette = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nSuggested k from Elbow method: {optimal_k_elbow}\")\n",
    "print(f\"Suggested k from Silhouette score: {optimal_k_silhouette}\")\n",
    "print(f\"Best silhouette score: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** Based on the plots, what is the optimal number of clusters? How do the Elbow method and Silhouette score agree or disagree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 2.2:** Perform K-means clustering and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2.2: Perform K-means clustering\n",
    "# Choose your optimal k\n",
    "optimal_k = # YOUR CHOICE\n",
    "\n",
    "if RAPIDS_AVAILABLE:\n",
    "    kmeans_final = # YOUR CODE HERE\n",
    "    kmeans_labels = kmeans_final.fit_predict(titanic_scaled)\n",
    "else:\n",
    "    kmeans_final = # YOUR CODE HERE\n",
    "    kmeans_labels = kmeans_final.fit_predict(titanic_scaled)\n",
    "\n",
    "# Add cluster labels to the data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"K-means clustering completed with {optimal_k} clusters\")\n",
    "print(\"\\nCluster distribution:\")\n",
    "print(titanic_with_clusters['Kmeans_Cluster'].value_counts().sort_index())\n",
    "\n",
    "# Analyze clusters\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"\\nCluster characteristics:\")\n",
    "display(cluster_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2:** What do the clusters represent? Can you describe the characteristics of each cluster in plain English?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Other Clustering Algorithms\n",
    "\n",
    "**TODO 3.1:** Try hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.1: Hierarchical clustering\n",
    "# Use a sample for efficiency\n",
    "sample_size = min(200, len(titanic_scaled))\n",
    "titanic_sample = # YOUR CODE HERE\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Add hierarchical cluster labels\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"Hierarchical clustering completed on {sample_size} samples with {optimal_k} clusters\")\n",
    "print(\"\\nHierarchical cluster distribution:\")\n",
    "print(titanic_sample_with_clusters['Hierarchical_Cluster'].value_counts().sort_index())\n",
    "\n",
    "# Compare with K-means on the sample\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** How do hierarchical clustering results compare to K-means? Which method do you prefer and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 3.2:** Experiment with DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3.2: DBSCAN clustering\n",
    "# Try different eps and min_samples values\n",
    "eps_values = [0.5, 0.8, 1.0]\n",
    "min_samples_values = [3, 5, 10]\n",
    "\n",
    "best_silhouette = -1\n",
    "best_params = None\n",
    "best_labels = None\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        if RAPIDS_AVAILABLE:\n",
    "            dbscan = # YOUR CODE HERE\n",
    "            labels = dbscan.fit_predict(titanic_scaled)\n",
    "        else:\n",
    "            dbscan = # YOUR CODE HERE\n",
    "            labels = dbscan.fit_predict(titanic_scaled)\n",
    "        \n",
    "        # Only evaluate if we have more than 1 cluster and some core points\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_core_points = (labels != -1).sum()\n",
    "        \n",
    "        if n_clusters > 1 and n_core_points > 10:\n",
    "            try:\n",
    "                sil_score = silhouette_score(titanic_scaled[labels != -1], labels[labels != -1])\n",
    "                if sil_score > best_silhouette:\n",
    "                    best_silhouette = sil_score\n",
    "                    best_params = (eps, min_samples)\n",
    "                    best_labels = labels\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "print(f\"Best DBSCAN parameters: eps={best_params[0]}, min_samples={best_params[1]}\")\n",
    "print(f\"Best silhouette score: {best_silhouette:.3f}\")\n",
    "\n",
    "# Analyze best DBSCAN results\n",
    "if best_labels is not None:\n",
    "    n_clusters = len(set(best_labels)) - (1 if -1 in best_labels else 0)\n",
    "    n_noise = list(best_labels).count(-1)\n",
    "    \n",
    "    print(f\"\\nNumber of clusters found: {n_clusters}\")\n",
    "    print(f\"Number of noise points: {n_noise} ({n_noise/len(titanic_scaled)*100:.1f}%)\")\n",
    "    \n",
    "    # Add to main dataframe\n",
    "    titanic_with_clusters['DBSCAN_Cluster'] = best_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** What does DBSCAN find that the other methods don't? When would you choose DBSCAN over K-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Dimensionality Reduction\n",
    "\n",
    "**TODO 4.1:** Apply PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.1: PCA dimensionality reduction\n",
    "# Apply PCA to reduce to 2 dimensions\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"PCA completed\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Create DataFrame with PCA results\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Plot PCA results colored by clusters\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1:** How much variance is explained by the first two principal components? What does this tell us about the data structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 4.2:** Try t-SNE for non-linear dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.2: t-SNE dimensionality reduction\n",
    "# Apply t-SNE to reduce to 2 dimensions\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create DataFrame with t-SNE results\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Plot t-SNE results\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2:** How does t-SNE visualization compare to PCA? Which one shows clearer cluster separation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 4.3:** Try UMAP if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4.3: UMAP dimensionality reduction (if available)\n",
    "if UMAP_AVAILABLE:\n",
    "    print(\"Performing UMAP dimensionality reduction...\")\n",
    "    \n",
    "    if RAPIDS_AVAILABLE:\n",
    "        # Use RAPIDS cuML UMAP\n",
    "        umap_reducer = # YOUR CODE HERE\n",
    "        titanic_umap = umap_reducer.fit_transform(titanic_scaled)\n",
    "    else:\n",
    "        # Use CPU UMAP\n",
    "        umap_reducer = # YOUR CODE HERE\n",
    "        titanic_umap = umap_reducer.fit_transform(titanic_scaled)\n",
    "    \n",
    "    # Create DataFrame with UMAP results\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Plot UMAP results\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"UMAP not available, skipping UMAP visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3:** Compare PCA, t-SNE, and UMAP. Which method works best for this dataset and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Clustering Evaluation and Interpretation\n",
    "\n",
    "**TODO 5.1:** Evaluate clustering quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5.1: Evaluate clustering quality\n",
    "# Use silhouette score, Calinski-Harabasz score, Davies-Bouldin score\n",
    "def evaluate_clustering(X, labels, method_name):\n",
    "    if len(set(labels)) > 1:\n",
    "        try:\n",
    "            silhouette = # YOUR CODE HERE\n",
    "            ch_score = # YOUR CODE HERE\n",
    "            db_score = # YOUR CODE HERE\n",
    "            \n",
    "            print(f\"\\n{method_name} Clustering Evaluation:\")\n",
    "            print(f\"Silhouette Score: {silhouette:.3f}\")\n",
    "            print(f\"Calinski-Harabasz Score: {ch_score:.3f}\")\n",
    "            print(f\"Davies-Bouldin Score: {db_score:.3f}\")\n",
    "            \n",
    "            return {\n",
    "                'silhouette': silhouette,\n",
    "                'ch_score': ch_score,\n",
    "                'db_score': db_score\n",
    "            }\n",
    "        except:\n",
    "            print(f\"\\n{method_name}: Could not calculate all metrics\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"\\n{method_name}: Only one cluster found\")\n",
    "        return None\n",
    "\n",
    "# Evaluate K-means\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Evaluate DBSCAN (only core points)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1:** Which clustering method performs best according to the metrics? What do these metrics tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 5.2:** Interpret the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": [],
   "source": [
    "# TODO 5.2: Interpret clusters\n",
    "# Analyze each cluster's characteristics\n",
    "print(\"\\n=== CLUSTER INTERPRETATION ===\")\n",
    "\n",
    "# Analyze K-means clusters in detail\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Compare clustering with survival patterns\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Show example passengers from each cluster\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2:** What real-world insights can you derive from the clusters? How do they relate to the survival patterns we know from supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Challenge (Optional)\n",
    "\n",
    "**TODO 6.1:** Try different preprocessing approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6.1: Advanced preprocessing (Optional)\n",
    "# Try different feature engineering approaches\n",
    "\n",
    "# Option 1: Include more categorical features\n",
    "# Option 2: Try different scaling methods\n",
    "# Option 3: Create interaction features\n",
    "\n",
    "# Example: Try without scaling some features\n",
    "# titanic_no_scale = titanic_clean.copy()\n",
    "# scaler_partial = StandardScaler()\n",
    "# features_to_scale = ['Age', 'Fare', 'Family_Size']\n",
    "# titanic_no_scale[features_to_scale] = scaler_partial.fit_transform(titanic_no_scale[features_to_scale])\n",
    "\n",
    "# Then compare clustering results\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Advanced preprocessing completed - compare results with basic approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Reflection\n",
    "\n",
    "**TODO:** Complete the summary questions below\n",
    "\n",
    "### Key Learnings:\n",
    "1. What was the most surprising discovery from your clustering analysis?\n",
    "2. Which clustering algorithm worked best for this dataset and why?\n",
    "3. How do dimensionality reduction techniques help understand the data?\n",
    "4. What are the practical applications of unsupervised learning on this dataset?\n",
    "5. How does unsupervised learning complement supervised learning?\n",
    "\n",
    "### Answers:\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n",
    "\n",
    "### Next Steps:\n",
    "- Try other clustering algorithms (Gaussian Mixture Models, Spectral Clustering)\n",
    "- Experiment with different distance metrics and linkage methods\n",
    "- Apply clustering to other datasets\n",
    "- Explore semi-supervised learning approaches\n",
    "- Try advanced dimensionality reduction techniques\n",
    "\n",
    "### Performance Notes:\n",
    "- RAPIDS acceleration: {\"Used\" if RAPIDS_AVAILABLE else \"Not used\"}\n",
    "- UMAP available: {\"Yes\" if UMAP_AVAILABLE else \"No\"}\n",
    "- Dataset size: {len(titanic_scaled)} samples, {titanic_scaled.shape[1]} features\n",
    "- Best clustering method: [Your choice]\n",
    "- Best dimensionality reduction: [Your choice]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}